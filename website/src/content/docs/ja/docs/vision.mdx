---
title: Code2Promptのビジョン
description: Code2Promptの背後にあるビジョンと、コードとのLLMインタラクションをどのように強化するかをご覧ください。
---

import { Card } from "@astrojs/starlight/components";
import { Aside } from "@astrojs/starlight/components";

<Card title="目的 🎯">
  `code2prompt`は、開発者とAIエージェントがコードベースと効果的に相互作用できるように支援するために作成されました。
</Card>

## 問題点 🚩

大規模言語モデル（LLM）は、コードとのインタラクション方法に革命をもたらしました。しかし、コード生成に関しては、まだ大きな課題に直面しています。

- **計画と推論**: LLMには計画と推論能力が欠けており、コード生成、リファクタリング、デバッグなどのタスクに不可欠です。彼らは全体像を把握するのに苦労することが多く、近視眼的です。
- **コンテキストサイズ**: LLMには限られたコンテキストウィンドウがあり、大きなコードベースを分析して理解する能力を制限します。
- **幻覚**: LLMは、正しいように見えるが、実際には正しくない、または意味をなさないコードを生成することがあります。この現象は、モデルがコードベースのコンテキストまたは理解を十分に持っていない場合に発生する幻覚と呼ばれます。

この問題を解決するために、`code2prompt`があります。

## 解決策 ✅

私たちは、計画と推論は、足場技術を使用することで、人間またはAIエージェントによって達成できると信じています。これらのエージェントは、タスクに適したフィルター処理された構造化されたフォーマットされた**高品質のコンテキスト**を収集する必要があります。

経験則は次のとおりです。

<Aside type="tip">
  > 可能な限り最小限のコンテキストを提供しますが、必要なだけ提供します。
</Aside>

これは、特に大きなコードベースの場合、実際に困難です。しかし、`code2prompt`は、開発者とAIエージェントがコードベースをより効果的に吸収できるように支援するシンプルなツールです。

これにより、コードベースのトラバース、ファイルのフィルタリング、LLMが理解できる構造化されたプロンプトへのフォーマットを自動化します。これにより、計画、推論、幻覚の課題を軽減できます。

次のセクションでは、`code2prompt`がこれらの課題にどのように取り組むように設計されているかを理解できます。

## アーキテクチャ ⛩️

<img
  src="/assets/images/architecture.svg"
  alt="code2promptのアーキテクチャ"
  style="width: 75%;"
/>

`code2prompt`はモジュール式に設計されており、さまざまなワークフローへの簡単な統合を可能にします。コアライブラリ、コマンドラインインターフェイス（CLI）、ソフトウェア開発キット（SDK）、またはモデルコンテキストプロトコル（MCP）サーバーとして使用できます。

### コア

`code2prompt`は、コード分析、生成、その他のタスクのためのLLMプロンプトを作成するプロセスを合理化するコード吸収ツールです。ディレクトリをトラバースし、ツリー構造を構築し、各ファイルに関する情報を収集することで動作します。コアライブラリは、他のアプリケーションに簡単に統合できます。

### CLI

`code2prompt`コマンドラインインターフェイス（CLI）は、コードベースからプロンプトを直接生成するために人間が使用できるように設計されています。生成されたプロンプトは自動的にクリップボードにコピーされ、出力ファイルに保存することもできます。さらに、Handlebarsテンプレートを使用してプロンプト生成をカスタマイズできます。ドキュメントに提供されているプロンプトを確認してください。

### SDK

`code2prompt`ソフトウェア開発キット（SDK）は、コアライブラリへのPythonバインディングを提供します。これは、コードベースとシームレスに相互作用したいAIエージェントまたは自動化スクリプトに最適です。SDKはPypiにホストされており、pip経由でインストールできます。

### MCP

`code2prompt`は、モデルコンテキストプロトコル（MCP）サーバーとしても利用でき、ローカルサービスとして実行できます。これにより、LLMにコードベースの構造化されたコンテキストを自動的に収集するツールを提供することで、LLMを強化できます。

> このページは便宜上、自動的に翻訳されています。元のコンテンツについては英語版を参照してください。
